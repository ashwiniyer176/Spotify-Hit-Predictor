{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Notebook\n",
    "\n",
    "This notebook is to be used for testing out the various models that you want to use. No preprocessing will be done in this notebook. Steps:\n",
    "\n",
    "1. Read in `input/train.csv`,`input/test.csv`,`input/validation.csv` that you created in the `Data Cleaning.ipynb`\n",
    "2. Train your model(s) on `input/train.csv` and EVALUATE (no training) with appropriate metrics (accuracy/MSE etc) on `input/validation.csv` \n",
    "3. Pick a final model and EVALUATE(no training) on `input/test.csv` and print metrics\n",
    "3. Pick a final model and save it as `models/model.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"../input/train.csv\")\n",
    "test_df=pd.read_csv(\"../input/test.csv\")\n",
    "validation_df=pd.read_csv(\"../input/validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_X_and_y(df):\n",
    "    return df.drop(columns=[\"target\"]),df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=return_X_and_y(train_df)\n",
    "X_test,y_test=return_X_and_y(test_df)\n",
    "X_val,y_val=return_X_and_y(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27541, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(layers.Dense(300,activation=\"relu\",input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(150,activation=\"relu\"))\n",
    "model.add(layers.Dense(150,activation=\"relu\"))\n",
    "model.add(layers.Dense(150,activation=\"relu\"))\n",
    "model.add(layers.Dense(75,activation=\"relu\"))\n",
    "model.add(layers.Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 300)               5400      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 150)               45150     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 75)                11325     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 76        \n",
      "=================================================================\n",
      "Total params: 107,251\n",
      "Trainable params: 107,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13798\n",
       "0    13743\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "276/276 [==============================] - 2s 5ms/step - loss: 0.5181 - accuracy: 0.7385 - val_loss: 0.4725 - val_accuracy: 0.7729\n",
      "Epoch 2/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4831 - accuracy: 0.7637 - val_loss: 0.4670 - val_accuracy: 0.7772\n",
      "Epoch 3/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4711 - accuracy: 0.7753 - val_loss: 0.4615 - val_accuracy: 0.7798\n",
      "Epoch 4/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4674 - accuracy: 0.7751 - val_loss: 0.4562 - val_accuracy: 0.7847\n",
      "Epoch 5/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4611 - accuracy: 0.7783 - val_loss: 0.4552 - val_accuracy: 0.7848\n",
      "Epoch 6/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4574 - accuracy: 0.7820 - val_loss: 0.4618 - val_accuracy: 0.7770\n",
      "Epoch 7/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4533 - accuracy: 0.7841 - val_loss: 0.4435 - val_accuracy: 0.7914\n",
      "Epoch 8/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4473 - accuracy: 0.7884 - val_loss: 0.4399 - val_accuracy: 0.7963\n",
      "Epoch 9/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4430 - accuracy: 0.7928 - val_loss: 0.4526 - val_accuracy: 0.7875\n",
      "Epoch 10/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4421 - accuracy: 0.7904 - val_loss: 0.4462 - val_accuracy: 0.7919\n",
      "Epoch 11/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4387 - accuracy: 0.7939 - val_loss: 0.4396 - val_accuracy: 0.7943\n",
      "Epoch 12/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4333 - accuracy: 0.7972 - val_loss: 0.4339 - val_accuracy: 0.8003\n",
      "Epoch 13/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4294 - accuracy: 0.7995 - val_loss: 0.4369 - val_accuracy: 0.7997\n",
      "Epoch 14/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4255 - accuracy: 0.8015 - val_loss: 0.4283 - val_accuracy: 0.8018\n",
      "Epoch 15/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4237 - accuracy: 0.8006 - val_loss: 0.4370 - val_accuracy: 0.7947\n",
      "Epoch 16/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4201 - accuracy: 0.8042 - val_loss: 0.4425 - val_accuracy: 0.7914\n",
      "Epoch 17/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4157 - accuracy: 0.8052 - val_loss: 0.4299 - val_accuracy: 0.8030\n",
      "Epoch 18/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4128 - accuracy: 0.8074 - val_loss: 0.4212 - val_accuracy: 0.8047\n",
      "Epoch 19/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4104 - accuracy: 0.8104 - val_loss: 0.4143 - val_accuracy: 0.8103\n",
      "Epoch 20/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.4055 - accuracy: 0.8112 - val_loss: 0.4248 - val_accuracy: 0.8041\n",
      "Epoch 21/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3997 - accuracy: 0.8147 - val_loss: 0.4188 - val_accuracy: 0.8056\n",
      "Epoch 22/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3983 - accuracy: 0.8155 - val_loss: 0.4183 - val_accuracy: 0.8099\n",
      "Epoch 23/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3943 - accuracy: 0.8201 - val_loss: 0.4145 - val_accuracy: 0.8101\n",
      "Epoch 24/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3896 - accuracy: 0.8204 - val_loss: 0.4123 - val_accuracy: 0.8140\n",
      "Epoch 25/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3860 - accuracy: 0.8228 - val_loss: 0.4141 - val_accuracy: 0.8112\n",
      "Epoch 26/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3812 - accuracy: 0.8264 - val_loss: 0.4150 - val_accuracy: 0.8118\n",
      "Epoch 27/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3762 - accuracy: 0.8299 - val_loss: 0.4159 - val_accuracy: 0.8152\n",
      "Epoch 28/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3742 - accuracy: 0.8290 - val_loss: 0.4107 - val_accuracy: 0.8132\n",
      "Epoch 29/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3697 - accuracy: 0.8329 - val_loss: 0.4196 - val_accuracy: 0.8128\n",
      "Epoch 30/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3641 - accuracy: 0.8344 - val_loss: 0.4195 - val_accuracy: 0.8153\n",
      "Epoch 31/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3603 - accuracy: 0.8376 - val_loss: 0.4150 - val_accuracy: 0.8192\n",
      "Epoch 32/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3566 - accuracy: 0.8398 - val_loss: 0.4272 - val_accuracy: 0.8161\n",
      "Epoch 33/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3515 - accuracy: 0.8414 - val_loss: 0.4101 - val_accuracy: 0.8159\n",
      "Epoch 34/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3460 - accuracy: 0.8426 - val_loss: 0.4331 - val_accuracy: 0.8130\n",
      "Epoch 35/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3440 - accuracy: 0.8429 - val_loss: 0.4553 - val_accuracy: 0.8150\n",
      "Epoch 36/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3392 - accuracy: 0.8482 - val_loss: 0.4199 - val_accuracy: 0.8185\n",
      "Epoch 37/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3353 - accuracy: 0.8501 - val_loss: 0.4263 - val_accuracy: 0.8195\n",
      "Epoch 38/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3301 - accuracy: 0.8527 - val_loss: 0.4424 - val_accuracy: 0.8172\n",
      "Epoch 39/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3272 - accuracy: 0.8521 - val_loss: 0.4314 - val_accuracy: 0.8263\n",
      "Epoch 40/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3218 - accuracy: 0.8580 - val_loss: 0.4282 - val_accuracy: 0.8238\n",
      "Epoch 41/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3176 - accuracy: 0.8569 - val_loss: 0.4220 - val_accuracy: 0.8274\n",
      "Epoch 42/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3155 - accuracy: 0.8600 - val_loss: 0.4711 - val_accuracy: 0.8199\n",
      "Epoch 43/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3085 - accuracy: 0.8618 - val_loss: 0.4347 - val_accuracy: 0.8251\n",
      "Epoch 44/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.3045 - accuracy: 0.8645 - val_loss: 0.4436 - val_accuracy: 0.8218\n",
      "Epoch 45/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2983 - accuracy: 0.8665 - val_loss: 0.4523 - val_accuracy: 0.8219\n",
      "Epoch 46/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2966 - accuracy: 0.8692 - val_loss: 0.4456 - val_accuracy: 0.8262\n",
      "Epoch 47/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2899 - accuracy: 0.8726 - val_loss: 0.4563 - val_accuracy: 0.8252\n",
      "Epoch 48/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2855 - accuracy: 0.8734 - val_loss: 0.4564 - val_accuracy: 0.8252\n",
      "Epoch 49/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2871 - accuracy: 0.8714 - val_loss: 0.4550 - val_accuracy: 0.8271\n",
      "Epoch 50/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2735 - accuracy: 0.8776 - val_loss: 0.4768 - val_accuracy: 0.8278\n",
      "Epoch 51/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2717 - accuracy: 0.8812 - val_loss: 0.4723 - val_accuracy: 0.8242\n",
      "Epoch 52/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2669 - accuracy: 0.8808 - val_loss: 0.5053 - val_accuracy: 0.8225\n",
      "Epoch 53/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2635 - accuracy: 0.8834 - val_loss: 0.4843 - val_accuracy: 0.8162\n",
      "Epoch 54/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2573 - accuracy: 0.8867 - val_loss: 0.4857 - val_accuracy: 0.8296\n",
      "Epoch 55/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2545 - accuracy: 0.8886 - val_loss: 0.5306 - val_accuracy: 0.8310\n",
      "Epoch 56/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2549 - accuracy: 0.8884 - val_loss: 0.4933 - val_accuracy: 0.8302\n",
      "Epoch 57/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2420 - accuracy: 0.8939 - val_loss: 0.5064 - val_accuracy: 0.8324\n",
      "Epoch 58/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2427 - accuracy: 0.8941 - val_loss: 0.5284 - val_accuracy: 0.8328\n",
      "Epoch 59/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2350 - accuracy: 0.8975 - val_loss: 0.5338 - val_accuracy: 0.8275\n",
      "Epoch 60/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2294 - accuracy: 0.9016 - val_loss: 0.5195 - val_accuracy: 0.8311\n",
      "Epoch 61/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2303 - accuracy: 0.9010 - val_loss: 0.5584 - val_accuracy: 0.8279\n",
      "Epoch 62/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2239 - accuracy: 0.9052 - val_loss: 0.6239 - val_accuracy: 0.8306\n",
      "Epoch 63/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2266 - accuracy: 0.9025 - val_loss: 0.5581 - val_accuracy: 0.8290\n",
      "Epoch 64/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2201 - accuracy: 0.9054 - val_loss: 0.5600 - val_accuracy: 0.8286\n",
      "Epoch 65/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2119 - accuracy: 0.9077 - val_loss: 0.5660 - val_accuracy: 0.8334\n",
      "Epoch 66/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2198 - accuracy: 0.9055 - val_loss: 0.5534 - val_accuracy: 0.8369\n",
      "Epoch 67/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2051 - accuracy: 0.9129 - val_loss: 0.5464 - val_accuracy: 0.8340\n",
      "Epoch 68/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2063 - accuracy: 0.9108 - val_loss: 0.5820 - val_accuracy: 0.8347\n",
      "Epoch 69/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.2029 - accuracy: 0.9122 - val_loss: 0.6067 - val_accuracy: 0.8279\n",
      "Epoch 70/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1995 - accuracy: 0.9141 - val_loss: 0.5602 - val_accuracy: 0.8414\n",
      "Epoch 71/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1886 - accuracy: 0.9199 - val_loss: 0.5872 - val_accuracy: 0.8348\n",
      "Epoch 72/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1912 - accuracy: 0.9176 - val_loss: 0.5893 - val_accuracy: 0.8330\n",
      "Epoch 73/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1793 - accuracy: 0.9250 - val_loss: 0.6417 - val_accuracy: 0.8353\n",
      "Epoch 74/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1822 - accuracy: 0.9229 - val_loss: 0.6234 - val_accuracy: 0.8342\n",
      "Epoch 75/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1822 - accuracy: 0.9219 - val_loss: 0.5889 - val_accuracy: 0.8365\n",
      "Epoch 76/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1804 - accuracy: 0.9225 - val_loss: 0.6408 - val_accuracy: 0.8405\n",
      "Epoch 77/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1757 - accuracy: 0.9260 - val_loss: 0.6485 - val_accuracy: 0.8371\n",
      "Epoch 78/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1823 - accuracy: 0.9238 - val_loss: 0.6630 - val_accuracy: 0.8404\n",
      "Epoch 79/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1708 - accuracy: 0.9264 - val_loss: 0.6458 - val_accuracy: 0.8322\n",
      "Epoch 80/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1677 - accuracy: 0.9287 - val_loss: 0.7299 - val_accuracy: 0.8340\n",
      "Epoch 81/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1647 - accuracy: 0.9304 - val_loss: 0.6645 - val_accuracy: 0.8337\n",
      "Epoch 82/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1520 - accuracy: 0.9372 - val_loss: 0.7410 - val_accuracy: 0.8389\n",
      "Epoch 83/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1603 - accuracy: 0.9332 - val_loss: 0.6713 - val_accuracy: 0.8241\n",
      "Epoch 84/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1601 - accuracy: 0.9333 - val_loss: 0.6468 - val_accuracy: 0.8411\n",
      "Epoch 85/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1466 - accuracy: 0.9383 - val_loss: 0.6942 - val_accuracy: 0.8410\n",
      "Epoch 86/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1553 - accuracy: 0.9349 - val_loss: 0.6756 - val_accuracy: 0.8315\n",
      "Epoch 87/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1474 - accuracy: 0.9384 - val_loss: 0.7043 - val_accuracy: 0.8333\n",
      "Epoch 88/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1375 - accuracy: 0.9444 - val_loss: 0.7568 - val_accuracy: 0.8401\n",
      "Epoch 89/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1458 - accuracy: 0.9401 - val_loss: 0.7013 - val_accuracy: 0.8438\n",
      "Epoch 90/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1350 - accuracy: 0.9446 - val_loss: 0.7675 - val_accuracy: 0.8403\n",
      "Epoch 91/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1395 - accuracy: 0.9427 - val_loss: 0.7347 - val_accuracy: 0.8362\n",
      "Epoch 92/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1339 - accuracy: 0.9455 - val_loss: 0.7517 - val_accuracy: 0.8353\n",
      "Epoch 93/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1349 - accuracy: 0.9442 - val_loss: 0.7244 - val_accuracy: 0.8432\n",
      "Epoch 94/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1261 - accuracy: 0.9476 - val_loss: 0.7812 - val_accuracy: 0.8354\n",
      "Epoch 95/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1239 - accuracy: 0.9504 - val_loss: 0.7811 - val_accuracy: 0.8373\n",
      "Epoch 96/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1233 - accuracy: 0.9501 - val_loss: 0.7689 - val_accuracy: 0.8351\n",
      "Epoch 97/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1294 - accuracy: 0.9472 - val_loss: 0.7464 - val_accuracy: 0.8446\n",
      "Epoch 98/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1171 - accuracy: 0.9536 - val_loss: 0.7761 - val_accuracy: 0.8341\n",
      "Epoch 99/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1271 - accuracy: 0.9506 - val_loss: 0.7284 - val_accuracy: 0.8415\n",
      "Epoch 100/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1141 - accuracy: 0.9544 - val_loss: 0.7722 - val_accuracy: 0.8379\n",
      "Epoch 101/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1077 - accuracy: 0.9565 - val_loss: 0.8089 - val_accuracy: 0.8360\n",
      "Epoch 102/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1256 - accuracy: 0.9494 - val_loss: 0.7598 - val_accuracy: 0.8425\n",
      "Epoch 103/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1087 - accuracy: 0.9557 - val_loss: 0.7724 - val_accuracy: 0.8429\n",
      "Epoch 104/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1146 - accuracy: 0.9540 - val_loss: 0.7912 - val_accuracy: 0.8370\n",
      "Epoch 105/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1050 - accuracy: 0.9584 - val_loss: 0.8038 - val_accuracy: 0.8328\n",
      "Epoch 106/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1115 - accuracy: 0.9561 - val_loss: 0.7494 - val_accuracy: 0.8367\n",
      "Epoch 107/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1067 - accuracy: 0.9575 - val_loss: 0.8158 - val_accuracy: 0.8420\n",
      "Epoch 108/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.0947 - accuracy: 0.9638 - val_loss: 0.8129 - val_accuracy: 0.8428\n",
      "Epoch 109/300\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.1036 - accuracy: 0.9588 - val_loss: 0.8086 - val_accuracy: 0.8366\n",
      "Epoch 110/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.1024 - accuracy: 0.9594 - val_loss: 0.8570 - val_accuracy: 0.8453\n",
      "Epoch 111/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.1039 - accuracy: 0.9588 - val_loss: 0.8493 - val_accuracy: 0.8309\n",
      "Epoch 112/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.0917 - accuracy: 0.9624 - val_loss: 0.8666 - val_accuracy: 0.8366\n",
      "Epoch 113/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.1063 - accuracy: 0.9573 - val_loss: 0.7827 - val_accuracy: 0.8438\n",
      "Epoch 114/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.0908 - accuracy: 0.9639 - val_loss: 0.8500 - val_accuracy: 0.8423\n",
      "Epoch 115/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.0975 - accuracy: 0.9615 - val_loss: 0.9301 - val_accuracy: 0.8333\n",
      "Epoch 116/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.1026 - accuracy: 0.9604 - val_loss: 0.8495 - val_accuracy: 0.8428\n",
      "Epoch 117/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.0893 - accuracy: 0.9649 - val_loss: 0.8228 - val_accuracy: 0.8410\n",
      "Epoch 118/300\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.0860 - accuracy: 0.9658 - val_loss: 0.9098 - val_accuracy: 0.8389\n",
      "Epoch 119/300\n",
      "248/276 [=========================>....] - ETA: 0s - loss: 0.0915 - accuracy: 0.9635"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ashwin\\Projects\\Spotify-Hit-Predictor\\notebooks\\Model Building.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ashwin/Projects/Spotify-Hit-Predictor/notebooks/Model%20Building.ipynb#ch0000010?line=0'>1</a>\u001b[0m history\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit(X_train,y_train,batch_size\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,epochs\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m(X_val,y_val))\n",
      "File \u001b[1;32mc:\\Users\\Ashwin\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1193\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1187\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1188\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1189\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1190\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1191\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1192\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1193\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1194\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1195\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Ashwin\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Ashwin\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Ashwin\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3040\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Ashwin\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1964\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Ashwin\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Ashwin\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=100,epochs=100,validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b9cbb540a0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"],color=\"red\")\n",
    "plt.plot(history.history[\"val_loss\"],color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "197295b20122369b6502e224a1410f8bc9b22cbbcad42d16b957c3154cf64235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
